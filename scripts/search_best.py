import os
import re
import argparse
import pandas as pd

# ----------------------
# å‘½ä»¤è¡Œå‚æ•°
# ----------------------
parser = argparse.ArgumentParser(description="search")
parser.add_argument("--log_dir", type=str, default="./logs", help="æ—¥å¿—ç›®å½•")
parser.add_argument(
    "--select", type=str, default="min",
    help="{min 96,192,320,512}"
)
args = parser.parse_args()

log_dir = args.log_dir
select_mode = args.select.strip().lower()

allowed_seq_lens = {"96", "192", "320", "512"}
if select_mode != "min" and select_mode not in allowed_seq_lens:
    raise ValueError(f"--select åªèƒ½æ˜¯ 'min' æˆ– {sorted(allowed_seq_lens)} ä¹‹ä¸€ï¼Œå½“å‰ä¸ºï¼š{args.select}")

# ----------------------
# æ­£åˆ™ä¸å®¹å™¨
# ----------------------

pattern_metrics = re.compile(r"mse[:=]\s*([0-9.]+)[, ]+mae[:=]\s*([0-9.]+)", re.IGNORECASE)
pattern_filename = re.compile(
    r'(?P<dataset>\w+?)_(?P<seq_len>\d+)_(?P<pred_len>\d+)_(?P<d_model>\d+)_(?P<d_ff>\d+)_e(?P<e_layers>\d+)_ep(?P<epochs>\d+)_lr(?P<lr>[\deE\.-]+)_(?P<model>\w+)\.log$'
)

best_results = {}  # key: (dataset, model, pred_len) -> record dict

# ----------------------
# éå†æ—¥å¿—
# ----------------------
for filename in os.listdir(log_dir):
    if not filename.endswith(".log"):
        continue

    match_file = pattern_filename.match(filename)
    if not match_file:
        continue

    file_info = match_file.groupdict()

    # å¦‚æœæŒ‡å®šäº†å›ºå®šè¾“å…¥é•¿åº¦ï¼Œä»…ä¿ç•™è¯¥ seq_len
    if select_mode != "min" and file_info["seq_len"] != select_mode:
        continue

    key = (file_info['dataset'], file_info['model'], int(file_info['pred_len']))
    log_path = os.path.join(log_dir, filename)

    try:
        with open(log_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()
        match_metric = pattern_metrics.search(content)
        if not match_metric:
            continue
        mse = float(match_metric.group(1))
        mae = float(match_metric.group(2))
        avg_score = (mse + mae) / 2.0
        # avg_score = (mse) / 2.0
    except Exception:
        continue

    if (key not in best_results) or (avg_score < best_results[key]['avg_score']):
        # è®°å½•æœ€ä¼˜ï¼ˆä»¥ avg_score ä¸ºå‡†ï¼‰
        best_results[key] = {
            'dataset': file_info['dataset'],
            'model': file_info['model'],
            'pred_len': int(file_info['pred_len']),
            'seq_len': int(file_info['seq_len']),
            'd_model': int(file_info['d_model']),
            'd_ff': int(file_info['d_ff']),
            'e_layers': int(file_info['e_layers']),
            'epochs': int(file_info['epochs']),
            'lr': float(file_info['lr']),
            'mse': mse,
            'mae': mae,
            'avg_score': avg_score,
            'log_file': filename
        }

# ----------------------
# è¾“å‡ºç»“æœ
# ----------------------
if not best_results:
    print("æœªæ‰¾åˆ°åŒ¹é…çš„æœ€ä¼˜ç»“æœã€‚è¯·æ£€æŸ¥æ—¥å¿—ç›®å½•ã€æ–‡ä»¶å‘½åæˆ– --select è®¾ç½®ã€‚")
    raise SystemExit(0)

df = pd.DataFrame(best_results.values())
df = df.sort_values(by=["dataset", "pred_len", "model"])

# ä¿å­˜ CSV
out_csv = "best_results.csv" if select_mode == "min" else f"best_results_seq{select_mode}.csv"
df.to_csv(out_csv, index=False)

# Markdown è¡¨æ ¼ï¼ˆå« avg_score ä»¥ä¾¿æ ¸å¯¹ï¼‰
#  "mse", "mae", "avg_score", , "log_file"
print(f"\nğŸ“‹ æœ€ä¼˜å‚æ•°è¡¨æ ¼ï¼ˆé€‰æ‹©æ¨¡å¼: {select_mode}ï¼‰\n")
print(df[[
    "dataset", "model", "pred_len",
    "seq_len", "d_model", "d_ff", "e_layers", "epochs", "lr"
]].to_markdown(index=False))

print("\n\nğŸ“Š æ¨¡å‹å¯¹æ¯”è¡¨ï¼ˆé€æ•°æ®é›† & é¢„æµ‹é•¿åº¦ï¼‰ï¼š\n")

datasets = sorted(df['dataset'].unique())
for dataset in datasets:
    subset = df[df["dataset"] == dataset]
    models = sorted(subset["model"].unique())
    pred_lens = sorted(subset["pred_len"].unique())

    print(f"\n### Dataset: {dataset}\n")
    header = ["Pred"] + models
    print(" | ".join(header))
    print("-" * (len(header) * 18))

    # æ”¶é›†æ¯ä¸ªæ¨¡å‹è·¨ä¸åŒ pred_len çš„ (mse, mae) ä»¥ä¾¿ç»“å°¾æ±‚å‡å€¼
    avg_scores = {model: [] for model in models}

    for pred in pred_lens:
        row = [str(pred)]
        for model in models:
            record = subset[(subset["model"] == model) & (subset["pred_len"] == pred)]
            if not record.empty:
                mse_v = record.iloc[0]["mse"]
                mae_v = record.iloc[0]["mae"]
                row.append(f"{mse_v:.3f}, {mae_v:.3f}")
                avg_scores[model].append((mse_v, mae_v))
            else:
                row.append(" - ")
        print(" | ".join(row))

    # æ¯ä¸ªæ¨¡å‹åœ¨è¯¥æ•°æ®é›†ä¸‹æ‰€æœ‰é¢„æµ‹é•¿åº¦çš„å¹³å‡ (mse, mae)
    avg_row = ["AVG"]
    for model in models:
        scores = avg_scores[model]
        if scores:
            mse_avg = sum(s[0] for s in scores) / len(scores)
            mae_avg = sum(s[1] for s in scores) / len(scores)
            avg_row.append(f"{mse_avg:.3f}, {mae_avg:.3f}")
        else:
            avg_row.append(" - ")
    print(" | ".join(avg_row))

print(f"\nâœ… å·²ä¿å­˜ CSVï¼š{out_csv}")
